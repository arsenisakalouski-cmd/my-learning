# –î–µ–Ω—å 29: –í–≤–µ–¥–µ–Ω–∏–µ –≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏

## üéØ –ß—Ç–æ –∏–∑—É—á–∏–ª–∏:

### 1. –û—Å–Ω–æ–≤—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π
- –ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–µ–π—Ä–æ–Ω (–±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π)
- –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω (–ø—Ä–æ—Å—Ç–µ–π—à–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å)
- –û–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø—Ä–∏–º–µ—Ä—ã
- –ü–æ—á–µ–º—É –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω –Ω–µ –º–æ–∂–µ—Ç XOR

### 2. –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ —Å–µ—Ç–∏ (MLP)
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –≤—Ö–æ–¥ ‚Üí —Å–∫—Ä—ã—Ç—ã–µ ‚Üí –≤—ã—Ö–æ–¥
- –§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (sigmoid, ReLU, tanh)
- –ü—Ä—è–º–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ (forward)
- –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ (backward)
- –†–µ—à–µ–Ω–∏–µ XOR —Å –ø–æ–º–æ—â—å—é MLP

### 3. Keras/TensorFlow
- –ü—Ä–æ—Å—Ç–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π
- Sequential –º–æ–¥–µ–ª—å
- Dense —Å–ª–æ–∏
- –ö–æ–º–ø–∏–ª—è—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

### 4. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ
- –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª ML —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏
- –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞

## üìÅ –§–∞–π–ª—ã:
```
Day 29/
‚îú‚îÄ‚îÄ 00_intro.txt                  # –û–±–∑–æ—Ä —Ç–µ–º—ã
‚îú‚îÄ‚îÄ 01_perceptron.py             # –ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω —Å –Ω—É–ª—è
‚îú‚îÄ‚îÄ 02_multilayer_network.py     # MLP —Å –Ω—É–ª—è
‚îú‚îÄ‚îÄ 03_keras_intro.py            # –ü–µ—Ä–≤–∞—è —Å–µ—Ç—å –Ω–∞ Keras
‚îú‚îÄ‚îÄ 04_simple_example.py         # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä
‚îú‚îÄ‚îÄ 05_final_test.py             # –ò—Ç–æ–≥–æ–≤—ã–π —Ç–µ—Å—Ç
‚îî‚îÄ‚îÄ README.md                    # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## üß† –ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω (1 –Ω–µ–π—Ä–æ–Ω):

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
```
–í—Ö–æ–¥—ã ‚Üí –í–µ—Å–∞ ‚Üí –°—É–º–º–∞ ‚Üí –ê–∫—Ç–∏–≤–∞—Ü–∏—è ‚Üí –í—ã—Ö–æ–¥
X1 ‚îÄ‚îÄ‚îê
X2 ‚îÄ‚îÄ‚î§‚îÄ‚îÄ> Œ£ ‚îÄ‚îÄ> f() ‚îÄ‚îÄ> y
X3 ‚îÄ‚îÄ‚îò
```

### –§–æ—Ä–º—É–ª–∞:
```python
z = X1*W1 + X2*W2 + X3*W3 + bias
y = activation(z)
```

### –û–±—É—á–µ–Ω–∏–µ:
```python
W_new = W_old + learning_rate * error * X
error = y_true - y_pred
```

### –ß—Ç–æ –º–æ–∂–µ—Ç/–Ω–µ –º–æ–∂–µ—Ç:
- ‚úì AND, OR (–ª–∏–Ω–µ–π–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–º—ã–µ)
- ‚úó XOR (–Ω–µ–ª–∏–Ω–µ–π–Ω–∞—è –∑–∞–¥–∞—á–∞)

### –ö–æ–¥:
```python
class Perceptron:
    def __init__(self, n_inputs):
        self.weights = np.random.randn(n_inputs)
        self.bias = np.random.randn()
    
    def predict(self, X):
        z = np.dot(X, self.weights) + self.bias
        return 1 if z >= 0 else 0
    
    def train(self, X, y, epochs=100):
        for epoch in range(epochs):
            for xi, yi in zip(X, y):
                prediction = self.predict(xi)
                error = yi - prediction
                self.weights += learning_rate * error * xi
                self.bias += learning_rate * error
```

## üß† MLP (–º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è —Å–µ—Ç—å):

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
```
–í—Ö–æ–¥ (3)    –°–∫—Ä—ã—Ç—ã–π (4)    –í—ã—Ö–æ–¥ (1)
  X1 ‚îÄ‚îÄ‚îê       H1 ‚îÄ‚îÄ‚îê
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ> Y
  X2 ‚îÄ‚îÄ‚î§       H2 ‚îÄ‚îÄ‚î§
       ‚îÇ       H3 ‚îÄ‚îÄ‚î§
  X3 ‚îÄ‚îÄ‚îò       H4 ‚îÄ‚îÄ‚îò
```

### –§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏:

**Sigmoid:**
```python
def sigmoid(z):
    return 1 / (1 + np.exp(-z))
```
- –í—ã—Ö–æ–¥: (0, 1)
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)

**ReLU:**
```python
def relu(z):
    return np.maximum(0, z)
```
- –í—ã—Ö–æ–¥: [0, ‚àû)
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏ (–ø–æ–ø—É–ª—è—Ä–Ω–∞!)

**Tanh:**
```python
def tanh(z):
    return np.tanh(z)
```
- –í—ã—Ö–æ–¥: (-1, 1)
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏

### –ö–æ–¥ (—É–ø—Ä–æ—â—ë–Ω–Ω–æ):
```python
class MLP:
    def forward(self, X):
        # –°–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π
        z1 = X @ W1 + b1
        a1 = sigmoid(z1)
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        z2 = a1 @ W2 + b2
        a2 = sigmoid(z2)
        
        return a2
    
    def backward(self, X, y, output):
        # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
        output_error = output - y
        output_delta = output_error * sigmoid_derivative(z2)
        
        hidden_error = output_delta @ W2.T
        hidden_delta = hidden_error * sigmoid_derivative(z1)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
        W2 -= learning_rate * a1.T @ output_delta
        W1 -= learning_rate * X.T @ hidden_delta
```

## üöÄ Keras - –ø—Ä–æ—Å—Ç–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ:

### –¢—Ä–∏ —à–∞–≥–∞:
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# 1. –°–û–ó–î–ê–¢–¨
model = Sequential([
    Dense(8, activation='relu', input_shape=(3,)),  # —Å–∫—Ä—ã—Ç—ã–π
    Dense(4, activation='relu'),                     # —Å–∫—Ä—ã—Ç—ã–π
    Dense(1, activation='sigmoid')                   # –≤—ã—Ö–æ–¥
])

# 2. –ù–ê–°–¢–†–û–ò–¢–¨
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# 3. –û–ë–£–ß–ò–¢–¨
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2
)
```

### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:

**Sequential:**
- –ú–æ–¥–µ–ª—å –≥–¥–µ —Å–ª–æ–∏ –∏–¥—É—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ

**Dense:**
- –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π
- Dense(8) = 8 –Ω–µ–π—Ä–æ–Ω–æ–≤

**Optimizer:**
- `adam` - —Å–∞–º—ã–π –ø–æ–ø—É–ª—è—Ä–Ω—ã–π (—É–º–Ω—ã–π gradient descent)
- `sgd` - –ø—Ä–æ—Å—Ç–æ–π gradient descent
- `rmsprop` - –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ adam

**Loss:**
- `binary_crossentropy` - –¥–ª—è 2 –∫–ª–∞—Å—Å–æ–≤ (0/1)
- `categorical_crossentropy` - –¥–ª—è 3+ –∫–ª–∞—Å—Å–æ–≤
- `mse` - –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏

**Metrics:**
- `accuracy` - –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö
- `mae` - —Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞

### –í–∞–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
```python
epochs=100          # —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø—Ä–æ–π—Ç–∏ –ø–æ –¥–∞–Ω–Ω—ã–º
batch_size=32       # –æ–±–Ω–æ–≤–ª—è—Ç—å –≤–µ—Å–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥—ã—Ö 32 –ø—Ä–∏–º–µ—Ä–æ–≤
validation_split=0.2  # 20% train ‚Üí –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
verbose=1           # –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
```

## üìä –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–∫—É–ø–∫–∏):
```python
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# 1. –î–∞–Ω–Ω—ã–µ
X = –¥–∞–Ω–Ω—ã–µ –æ –∫–ª–∏–µ–Ω—Ç–∞—Ö (–≤–æ–∑—Ä–∞—Å—Ç, –¥–æ—Ö–æ–¥, –≤—Ä–µ–º—è)
y = –∫—É–ø–∏–ª –∏–ª–∏ –Ω–µ—Ç (0/1)

# 2. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (–í–ê–ñ–ù–û!)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. –ú–æ–¥–µ–ª—å
model = Sequential([
    Dense(8, activation='relu', input_shape=(3,)),
    Dense(4, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# 4. –û–±—É—á–µ–Ω–∏–µ
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2
)

# 5. –û—Ü–µ–Ω–∫–∞
test_acc = model.evaluate(X_test, y_test)[1]
print(f"Accuracy: {test_acc:.2%}")

# 6. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
new_data = scaler.transform([[25, 80, 30]])
prediction = model.predict(new_data)
print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {prediction[0][0]:.1%}")
```

## üí° –í–∞–∂–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏:

### –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ (–ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏):

1. **–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥:** –¥–∞–Ω–Ω—ã–µ –∏–¥—É—Ç –≤–ø–µ—Ä—ë–¥ —á–µ—Ä–µ–∑ —Å–ª–æ–∏
2. **–°—á–∏—Ç–∞–µ–º –æ—à–∏–±–∫—É:** —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤—ã—Ö–æ–¥ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º
3. **–û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥:** –æ—à–∏–±–∫–∞ –∏–¥—ë—Ç –Ω–∞–∑–∞–¥, –æ–±–Ω–æ–≤–ª—è—è –≤–µ—Å–∞
4. **–ü–æ–≤—Ç–æ—Ä—è–µ–º:** –º–Ω–æ–≥–æ —Ä–∞–∑ –ø–æ–∫–∞ –Ω–µ –Ω–∞—É—á–∏—Ç—Å—è

### –ó–∞—á–µ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ:

**–ë–ï–ó –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è:**
- –í–æ–∑—Ä–∞—Å—Ç: 20-70
- –î–æ—Ö–æ–¥: 20000-150000
- –°–µ—Ç—å –¥—É–º–∞–µ—Ç —á—Ç–æ –¥–æ—Ö–æ–¥ –≤–∞–∂–Ω–µ–µ!

**–° –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º:**
- –í—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: –ø—Ä–∏–º–µ—Ä–Ω–æ -2 –¥–æ 2
- –°–µ—Ç—å –≤–∏–¥–∏—Ç –≤—Å–µ —Ä–∞–≤–Ω—ã–º–∏

### –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ:

**–•–û–†–û–®–û:**
- Train: 85%, Test: 82% ‚úì

**–ü–õ–û–•–û (–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ):**
- Train: 99%, Test: 65% ‚úó

**–ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö:**
- Train loss –ø–∞–¥–∞–µ—Ç, Validation —Ä–∞—Å—Ç—ë—Ç ‚Üí –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ

### –ö–∞–∫ —É–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å:

1. **–ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö** - –ª—É—á—à–µ –≤—Å–µ–≥–æ!
2. **–ë–æ–ª—å—à–µ —ç–ø–æ—Ö** - –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è
3. **–ë–æ–ª—å—à–µ –Ω–µ–π—Ä–æ–Ω–æ–≤** - –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ (–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ)
4. **Dropout** - —Å–ª—É—á–∞–π–Ω–æ –æ—Ç–∫–ª—é—á–∞—Ç—å –Ω–µ–π—Ä–æ–Ω—ã (–¥–µ–Ω—å 30)
5. **Regularization** - —à—Ç—Ä–∞—Ñ–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ –≤–µ—Å–∞ (–¥–µ–Ω—å 30)

## üéì –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:

**–î–µ–Ω—å 30:**
- –£–ª—É—á—à–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π (Dropout, Batch Normalization)
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞
- Callbacks
- Early Stopping
- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–µ–∫—Ç—ã

**–î–∞–ª—å—à–µ:**
- CNN –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- RNN –¥–ª—è —Ç–µ–∫—Å—Ç–∞
- Transfer Learning
- –†–µ–∞–ª—å–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã

## ‚úÖ –ß–µ–∫-–ª–∏—Å—Ç –æ—Å–≤–æ–µ–Ω–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤:

- [x] –ü–æ–Ω–∏–º–∞—é —á—Ç–æ —Ç–∞–∫–æ–µ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω
- [x] –ü–æ–Ω–∏–º–∞—é –ø–æ—á–µ–º—É –Ω—É–∂–Ω—ã –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ —Å–µ—Ç–∏
- [x] –ó–Ω–∞—é —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏ –∫–æ–≥–¥–∞ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
- [x] –ü–æ–Ω–∏–º–∞—é —á—Ç–æ —Ç–∞–∫–æ–µ –æ–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ (–æ–±—â–∞—è –∏–¥–µ—è)
- [x] –£–º–µ—é —Å–æ–∑–¥–∞–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ Keras
- [x] –ó–Ω–∞—é –ø—Ä–æ—Ü–µ—Å—Å: —Å–æ–∑–¥–∞—Ç—å ‚Üí –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å ‚Üí –æ–±—É—á–∏—Ç—å ‚Üí –æ—Ü–µ–Ω–∏—Ç—å
- [x] –ü–æ–Ω–∏–º–∞—é –≤–∞–∂–Ω–æ—Å—Ç—å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
- [x] –ü–æ–Ω–∏–º–∞—é —á—Ç–æ —Ç–∞–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
- [x] –ú–æ–≥—É –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã:

- [Keras Documentation](https://keras.io/)
- [TensorFlow Tutorials](https://www.tensorflow.org/tutorials)
- [Neural Networks Playground](https://playground.tensorflow.org/) - –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

---

**–ü–æ–∑–¥—Ä–∞–≤–ª—è—é! –í—ã –æ—Å–≤–æ–∏–ª–∏ –æ—Å–Ω–æ–≤—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π! üß†üéâ**

**–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–≤–æ–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á!**