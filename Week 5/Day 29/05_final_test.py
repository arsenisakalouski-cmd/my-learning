# 05_final_test.py - Itogovyy test po neyrosetyam

import numpy as np
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import warnings
warnings.filterwarnings('ignore')

print("="*60)
print("–ò–¢–û–ì–û–í–´–ô –¢–ï–°–¢: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–Ω–∏–º–∞–Ω–∏—è")
print("="*60)

print("""
–°–µ–π—á–∞—Å –≤—ã —Å–æ–∑–¥–∞–¥–∏—Ç–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –°–ê–ú–ò!

–ó–ê–î–ê–ß–ê: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ü–≤–µ—Ç–æ–≤ Iris

–£ –≤–∞—Å –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Ü–≤–µ—Ç–∫–∞—Ö:
- sepal_length (–¥–ª–∏–Ω–∞ —á–∞—à–µ–ª–∏—Å—Ç–∏–∫–∞)
- sepal_width (—à–∏—Ä–∏–Ω–∞ —á–∞—à–µ–ª–∏—Å—Ç–∏–∫–∞)
- petal_length (–¥–ª–∏–Ω–∞ –ª–µ–ø–µ—Å—Ç–∫–∞)
- petal_width (—à–∏—Ä–∏–Ω–∞ –ª–µ–ø–µ—Å—Ç–∫–∞)

–ù–∞–¥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–∏–¥:
- 0 = setosa
- 1 = versicolor
- 2 = virginica

–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–¥–µ–ª–∞—Ç—å —Å–∞–º–∏!
""")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

iris = load_iris()
X = iris.data
y = iris.target

print(f"–î–∞–Ω–Ω—ã—Ö: {len(X)}")
print(f"–ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")
print(f"–ö–ª–∞—Å—Å–æ–≤: {len(np.unique(y))}")

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

print(f"\nTrain: {len(X_train)}")
print(f"Test: {len(X_test)}")

# ============================================
# VASH KOD ZDES!
# ============================================

print("\n" + "="*60)
print("–°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å...")
print("="*60)

# –ü–û–î–°–ö–ê–ó–ö–ê: –≠—Ç–æ –∑–∞–¥–∞—á–∞ —Å 3 –∫–ª–∞—Å—Å–∞–º–∏!
# –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å Dense(3, activation='softmax')
# softmax - –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

model = Sequential([
    Dense(8, activation='relu', input_shape=(4,)),
    Dense(6, activation='relu'),
    Dense(3, activation='softmax')  # 3 –∫–ª–∞—Å—Å–∞!
])
"""
–ù–û–í–û–ï: softmax –≤–º–µ—Å—Ç–æ sigmoid!

sigmoid - –¥–ª—è 2 –∫–ª–∞—Å—Å–æ–≤ (0 –∏–ª–∏ 1)
softmax - –¥–ª—è 3+ –∫–ª–∞—Å—Å–æ–≤ (0, 1, 2, ...)

softmax –¥–∞—ë—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –ö–ê–ñ–î–û–ì–û –∫–ª–∞—Å—Å–∞:
[0.1, 0.7, 0.2] = 10% —á—Ç–æ –∫–ª–∞—Å—Å 0, 70% —á—Ç–æ –∫–ª–∞—Å—Å 1, 20% —á—Ç–æ –∫–ª–∞—Å—Å 2
–°—É–º–º–∞ = 1.0
"""

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',  # –¥–ª—è 3+ –∫–ª–∞—Å—Å–æ–≤
    metrics=['accuracy']
)
"""
–ù–û–í–û–ï: sparse_categorical_crossentropy

binary_crossentropy - –¥–ª—è 2 –∫–ª–∞—Å—Å–æ–≤
sparse_categorical_crossentropy - –¥–ª—è 3+ –∫–ª–∞—Å—Å–æ–≤

'sparse' –æ–∑–Ω–∞—á–∞–µ—Ç —á—Ç–æ y = [0, 1, 2]
(–±–µ–∑ sparse –Ω–∞–¥–æ y = [[1,0,0], [0,1,0], [0,0,1]])
"""

print("–û–±—É—á–∞–µ–º...")
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=16,
    validation_split=0.2,
    verbose=0
)

# –û—Ü–µ–Ω–∫–∞
test_acc = model.evaluate(X_test, y_test, verbose=0)[1]

print(f"\n‚úì –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
print(f"Test Accuracy: {test_acc:.2%}")

if test_acc > 0.90:
    print("üéâ –û–¢–õ–ò–ß–ù–û! –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ!")
elif test_acc > 0.80:
    print("üëç –•–æ—Ä–æ—à–æ! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ª—É—á—à–∏—Ç—å!")
else:
    print("ü§î –ú–æ–∂–Ω–æ –ª—É—á—à–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
    print("  - –ë–æ–ª—å—à–µ —ç–ø–æ—Ö")
    print("  - –ë–æ–ª—å—à–µ –Ω–µ–π—Ä–æ–Ω–æ–≤")
    print("  - –î—Ä—É–≥—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É")

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
print("\n–ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
sample = X_test[:3]
predictions = model.predict(sample, verbose=0)

for i, (x, pred) in enumerate(zip(sample, predictions)):
    pred_class = np.argmax(pred)  # –∫–ª–∞—Å—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
    true_class = y_test[i]
    
    print(f"\n–¶–≤–µ—Ç–æ–∫ {i+1}:")
    print(f"  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: {pred}")
    print(f"  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω –∫–ª–∞—Å—Å: {pred_class} ({iris.target_names[pred_class]})")
    print(f"  –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª–∞—Å—Å: {true_class} ({iris.target_names[true_class]})")
    print(f"  {'‚úì –í–µ—Ä–Ω–æ!' if pred_class == true_class else '‚úó –û—à–∏–±–∫–∞'}")

print("\n" + "="*60)
print("–†–ï–ó–Æ–ú–ï –¢–ï–°–¢–ê:")
print("="*60)

print(f"""
–í–´ –°–û–ó–î–ê–õ–ò –ù–ï–ô–†–û–°–ï–¢–¨ –î–õ–Ø 3 –ö–õ–ê–°–°–û–í!

–ù–û–í–û–ï —á—Ç–æ —É–∑–Ω–∞–ª–∏:
- softmax –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
- sparse_categorical_crossentropy –¥–ª—è 3+ –∫–ª–∞—Å—Å–æ–≤
- np.argmax() –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–ª–∞—Å—Å–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
4 –≤—Ö–æ–¥–∞ ‚Üí 8 –Ω–µ–π—Ä–æ–Ω–æ–≤ ‚Üí 6 –Ω–µ–π—Ä–æ–Ω–æ–≤ ‚Üí 3 –≤—ã—Ö–æ–¥–∞

–†–ï–ó–£–õ–¨–¢–ê–¢:
Accuracy: {test_acc:.2%}

Iris - –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞ –≤ ML!
–í—ã –µ—ë —Ä–µ—à–∏–ª–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é! üéâ
""")

print("\n‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω!")
print("="*60)